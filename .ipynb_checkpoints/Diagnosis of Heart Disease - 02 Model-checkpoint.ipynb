{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547fdf43",
   "metadata": {},
   "source": [
    "# Building Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b3d035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c76ae",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f65eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path of the processed data\n",
    "processed_data_path = os.path.join(os.path.pardir,'data','processed')\n",
    "train_file_path = os.path.join(processed_data_path,'train.csv')\n",
    "test_file_path = os.path.join(processed_data_path,'test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8440d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_file_path)\n",
    "test_df = pd.read_csv(test_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c644d39",
   "metadata": {},
   "source": [
    "### diagnosis of heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe40e3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294 entries, 0 to 293\n",
      "Data columns (total 33 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Unnamed: 0              294 non-null    int64  \n",
      " 1   diagnosed               294 non-null    int64  \n",
      " 2   age                     294 non-null    float64\n",
      " 3   sex                     294 non-null    float64\n",
      " 4   trestbps                294 non-null    float64\n",
      " 5   chol                    294 non-null    int64  \n",
      " 6   fbs                     294 non-null    int64  \n",
      " 7   restecg                 294 non-null    int64  \n",
      " 8   thalach                 294 non-null    float64\n",
      " 9   exang                   294 non-null    int64  \n",
      " 10  oldpeak                 294 non-null    float64\n",
      " 11  slope                   294 non-null    int64  \n",
      " 12  ca                      294 non-null    float64\n",
      " 13  thal                    294 non-null    float64\n",
      " 14  num                     294 non-null    int64  \n",
      " 15  trestbps_Bin_very_low   294 non-null    int64  \n",
      " 16  trestbps_Bin_low        294 non-null    int64  \n",
      " 17  trestbps_Bin_high       294 non-null    int64  \n",
      " 18  trestbps_Bin_very_high  294 non-null    int64  \n",
      " 19  AgeState_MiddleAdult    294 non-null    int64  \n",
      " 20  AgeState_OldAdult       294 non-null    int64  \n",
      " 21  cp_1.0                  294 non-null    int64  \n",
      " 22  cp_2.0                  294 non-null    int64  \n",
      " 23  cp_3.0                  294 non-null    int64  \n",
      " 24  cp_4.0                  294 non-null    int64  \n",
      " 25  cat_A                   294 non-null    int64  \n",
      " 26  cat_B                   294 non-null    int64  \n",
      " 27  cat_C                   294 non-null    int64  \n",
      " 28  cat_D                   294 non-null    int64  \n",
      " 29  cat_E                   294 non-null    int64  \n",
      " 30  cat_F                   294 non-null    int64  \n",
      " 31  cat_G                   294 non-null    int64  \n",
      " 32  cat_Z                   294 non-null    int64  \n",
      "dtypes: float64(7), int64(26)\n",
      "memory usage: 75.9 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a58850a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 33 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Unnamed: 0              303 non-null    int64  \n",
      " 1   diagnosed               303 non-null    int64  \n",
      " 2   age                     303 non-null    float64\n",
      " 3   sex                     303 non-null    float64\n",
      " 4   trestbps                303 non-null    float64\n",
      " 5   chol                    303 non-null    int64  \n",
      " 6   fbs                     303 non-null    int64  \n",
      " 7   restecg                 303 non-null    int64  \n",
      " 8   thalach                 303 non-null    float64\n",
      " 9   exang                   303 non-null    int64  \n",
      " 10  oldpeak                 303 non-null    float64\n",
      " 11  slope                   303 non-null    int64  \n",
      " 12  ca                      303 non-null    float64\n",
      " 13  thal                    303 non-null    float64\n",
      " 14  num                     303 non-null    int64  \n",
      " 15  trestbps_Bin_very_low   303 non-null    int64  \n",
      " 16  trestbps_Bin_low        303 non-null    int64  \n",
      " 17  trestbps_Bin_high       303 non-null    int64  \n",
      " 18  trestbps_Bin_very_high  303 non-null    int64  \n",
      " 19  AgeState_MiddleAdult    303 non-null    int64  \n",
      " 20  AgeState_OldAdult       303 non-null    int64  \n",
      " 21  cp_1.0                  303 non-null    int64  \n",
      " 22  cp_2.0                  303 non-null    int64  \n",
      " 23  cp_3.0                  303 non-null    int64  \n",
      " 24  cp_4.0                  303 non-null    int64  \n",
      " 25  cat_A                   303 non-null    int64  \n",
      " 26  cat_B                   303 non-null    int64  \n",
      " 27  cat_C                   303 non-null    int64  \n",
      " 28  cat_D                   303 non-null    int64  \n",
      " 29  cat_E                   303 non-null    int64  \n",
      " 30  cat_F                   303 non-null    int64  \n",
      " 31  cat_G                   303 non-null    int64  \n",
      " 32  cat_Z                   303 non-null    int64  \n",
      "dtypes: float64(7), int64(26)\n",
      "memory usage: 78.2 KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8b1bd",
   "metadata": {},
   "source": [
    "### diagnosis of heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e1d2fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    164\n",
       "1     55\n",
       "2     36\n",
       "3     35\n",
       "4     13\n",
       "Name: num, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d41a06d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>diagnosed</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>...</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>cp_4.0</th>\n",
       "      <th>cat_A</th>\n",
       "      <th>cat_B</th>\n",
       "      <th>cat_C</th>\n",
       "      <th>cat_D</th>\n",
       "      <th>cat_E</th>\n",
       "      <th>cat_F</th>\n",
       "      <th>cat_G</th>\n",
       "      <th>cat_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  diagnosed   age  sex  trestbps  chol  fbs  restecg  thalach  \\\n",
       "0           0          0  28.0  1.0     130.0   132    0        2    185.0   \n",
       "1           1          0  29.0  1.0     120.0   243    0        0    160.0   \n",
       "2           2          0  29.0  1.0     140.0   242    0        0    170.0   \n",
       "3           3          0  30.0  0.0     170.0   237    0        1    170.0   \n",
       "4           4          0  31.0  0.0     100.0   219    0        1    150.0   \n",
       "\n",
       "   exang  ...  cp_3.0  cp_4.0  cat_A  cat_B  cat_C  cat_D  cat_E  cat_F  \\\n",
       "0      0  ...       0       0      0      0      0      0      0      1   \n",
       "1      0  ...       0       0      0      0      0      0      1      0   \n",
       "2      0  ...       0       0      0      0      0      0      1      0   \n",
       "3      0  ...       0       0      0      0      0      0      1      0   \n",
       "4      0  ...       0       0      0      0      0      1      0      0   \n",
       "\n",
       "   cat_G  cat_Z  \n",
       "0      0      0  \n",
       "1      0      0  \n",
       "2      0      0  \n",
       "3      0      0  \n",
       "4      0      0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27c8dc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>diagnosed</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>...</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>cp_4.0</th>\n",
       "      <th>cat_A</th>\n",
       "      <th>cat_B</th>\n",
       "      <th>cat_C</th>\n",
       "      <th>cat_D</th>\n",
       "      <th>cat_E</th>\n",
       "      <th>cat_F</th>\n",
       "      <th>cat_G</th>\n",
       "      <th>cat_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-888</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-888</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-888</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-888</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-888</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  diagnosed   age  sex  trestbps  chol  fbs  restecg  thalach  \\\n",
       "0           0       -888  63.0  1.0     145.0   233    1        2    150.0   \n",
       "1           1       -888  67.0  1.0     160.0   286    0        2    108.0   \n",
       "2           2       -888  67.0  1.0     120.0   229    0        2    129.0   \n",
       "3           3       -888  37.0  1.0     130.0   250    0        0    187.0   \n",
       "4           4       -888  41.0  0.0     130.0   204    0        2    172.0   \n",
       "\n",
       "   exang  ...  cp_3.0  cp_4.0  cat_A  cat_B  cat_C  cat_D  cat_E  cat_F  \\\n",
       "0      0  ...       0       0      0      0      0      1      0      0   \n",
       "1      1  ...       0       1      0      1      0      0      0      0   \n",
       "2      1  ...       0       1      0      0      1      0      0      0   \n",
       "3      0  ...       1       0      0      0      0      0      0      1   \n",
       "4      0  ...       0       0      0      0      0      0      1      0   \n",
       "\n",
       "   cat_G  cat_Z  \n",
       "0      0      0  \n",
       "1      0      0  \n",
       "2      0      0  \n",
       "3      0      0  \n",
       "4      0      0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36275a",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc609d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 33 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Unnamed: 0              303 non-null    int64  \n",
      " 1   diagnosed               303 non-null    int64  \n",
      " 2   age                     303 non-null    float64\n",
      " 3   sex                     303 non-null    float64\n",
      " 4   trestbps                303 non-null    float64\n",
      " 5   chol                    303 non-null    int64  \n",
      " 6   fbs                     303 non-null    int64  \n",
      " 7   restecg                 303 non-null    int64  \n",
      " 8   thalach                 303 non-null    float64\n",
      " 9   exang                   303 non-null    int64  \n",
      " 10  oldpeak                 303 non-null    float64\n",
      " 11  slope                   303 non-null    int64  \n",
      " 12  ca                      303 non-null    float64\n",
      " 13  thal                    303 non-null    float64\n",
      " 14  num                     303 non-null    int64  \n",
      " 15  trestbps_Bin_very_low   303 non-null    int64  \n",
      " 16  trestbps_Bin_low        303 non-null    int64  \n",
      " 17  trestbps_Bin_high       303 non-null    int64  \n",
      " 18  trestbps_Bin_very_high  303 non-null    int64  \n",
      " 19  AgeState_MiddleAdult    303 non-null    int64  \n",
      " 20  AgeState_OldAdult       303 non-null    int64  \n",
      " 21  cp_1.0                  303 non-null    int64  \n",
      " 22  cp_2.0                  303 non-null    int64  \n",
      " 23  cp_3.0                  303 non-null    int64  \n",
      " 24  cp_4.0                  303 non-null    int64  \n",
      " 25  cat_A                   303 non-null    int64  \n",
      " 26  cat_B                   303 non-null    int64  \n",
      " 27  cat_C                   303 non-null    int64  \n",
      " 28  cat_D                   303 non-null    int64  \n",
      " 29  cat_E                   303 non-null    int64  \n",
      " 30  cat_F                   303 non-null    int64  \n",
      " 31  cat_G                   303 non-null    int64  \n",
      " 32  cat_Z                   303 non-null    int64  \n",
      "dtypes: float64(7), int64(26)\n",
      "memory usage: 78.2 KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ea788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['diagnosed'] = test_df['num'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34756eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "201fe028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294, 33) (294,)\n",
      "(303, 33) (303,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=109)\n",
    "\n",
    "X_train = train_df\n",
    "y_train = train_df['diagnosed']\n",
    "\n",
    "X_test = test_df\n",
    "y_test = test_df['diagnosed'] #.ravel()\n",
    "\n",
    "\n",
    "print (X_train.shape,y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56326042",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b017cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3671b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model_lr_1 = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90c985bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model_lr_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b43d7804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for logistic regression - version 1 :0.52\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print('score for logistic regression - version 1 :{0:.2f}'.format(model_lr_1.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ebac6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.34252441e-01,  4.35828505e-02, -5.83052313e-01,\n",
       "        -2.96404731e-03, -1.23602987e-01, -1.87936610e-02,\n",
       "         2.00333609e-03, -1.21635721e-02, -7.87707688e-02,\n",
       "         4.12116435e-03, -5.94004657e-03,  1.99284967e-03,\n",
       "         0.00000000e+00, -7.17636924e-03,  4.35828505e-02,\n",
       "        -7.65908759e-03, -2.98628876e-02, -1.60856270e-03,\n",
       "         3.17820354e-02, -9.03445673e-03,  1.68595427e-03,\n",
       "        -3.55788423e-03, -1.44204437e-02,  2.54168087e-04,\n",
       "         1.03756574e-02, -2.57678541e-03, -7.35037528e-04,\n",
       "        -2.38737082e-02,  1.68721389e-02,  2.84517154e-03,\n",
       "         1.08650870e-04,  0.00000000e+00,  1.10674200e-05]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model coefficients\n",
    "model_lr_1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0cc352",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1190376b",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "930c6e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model\n",
    "model_lr = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dda6bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db448013",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':[1.0, 10.0, 50.0, 100.0, 1000.0], 'penalty':['l1','l2']}\n",
    "clf = GridSearchCV(model_lr, param_grid=parameters, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec28d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_test = test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a5c7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_test = test_df['num'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b507cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(random_state=0),\n",
       "             param_grid={'C': [1.0, 10.0, 50.0, 100.0, 1000.0],\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75b903f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7122a727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:0.71\n"
     ]
    }
   ],
   "source": [
    "print ('best score:{0:.2f}'.format(clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5996ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for logistic regression - version 2 :0.76\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print('score for logistic regression - version 2 :{0:.2f}'.format(clf.score(X2_test,y2_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adb74c7",
   "metadata": {},
   "source": [
    "## Feature Normalization and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b86b4fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6ba26b",
   "metadata": {},
   "source": [
    "### Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc46065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature normalization\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3616b54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled[:,0].min(),X_train_scaled[:,0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3cb3b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize test data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e588c13",
   "metadata": {},
   "source": [
    "### Feature Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3a253cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77915a60",
   "metadata": {},
   "source": [
    "### Create model after standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a24f555b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1.0, 10.0, 50.0, 100.0, 1000.0],\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base model\n",
    "model_lr = LogisticRegression()\n",
    "parameters={'C':[1.0,10.0,50.0, 100.0, 1000.0],'penalty':['l1','l2']}\n",
    "clf = GridSearchCV(model_lr,param_grid=parameters,cv=3)\n",
    "clf.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7fada51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_predict = clf.predict(X_test_scaled)\n",
    "rfc_predict[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd029f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       164\n",
      "           1       1.00      1.00      1.00       139\n",
      "\n",
      "    accuracy                           1.00       303\n",
      "   macro avg       1.00      1.00      1.00       303\n",
      "weighted avg       1.00      1.00      1.00       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluating Random Forest Classifier\n",
    "print(classification_report(y_test, rfc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56d53f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3f018b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for logistic regression - version 2: 1.00\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print ('score for logistic regression - version 2: {0:.2f}'.format(clf.score(X_test_scaled,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00a9405",
   "metadata": {},
   "source": [
    "## Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0b72c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle library\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a83accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the file paths\n",
    "model_file_path = os.path.join(os.path.pardir,'models','lr_model.pkl')\n",
    "scaler_file_path = os.path.join(os.path.pardir,'models','lr_scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49cec2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the files to write\n",
    "model_file_pickle = open(model_file_path,'wb')\n",
    "scaler_file_pickle = open(scaler_file_path,'wb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "274170d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist the model and scaler\n",
    "pickle.dump(clf,model_file_pickle)\n",
    "pickle.dump(scaler,scaler_file_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d50b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the file\n",
    "model_file_pickle.close()\n",
    "scaler_file_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb5e0bd",
   "metadata": {},
   "source": [
    "### load the persisted file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47e3e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open files in read mode\n",
    "model_file_pickle = open(model_file_path,'rb')\n",
    "scaler_file_pickle = open(scaler_file_path,'rb')\n",
    "# load files\n",
    "clf_loaded = pickle.load(model_file_pickle)\n",
    "scaler_loaded = pickle.load(scaler_file_pickle)\n",
    "#close files\n",
    "model_file_pickle.close()\n",
    "scaler_file_pickle.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad5c7122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1.0, 10.0, 50.0, 100.0, 1000.0],\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ad3602d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e16ba15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for persisted logistic regression :1.00\n"
     ]
    }
   ],
   "source": [
    "# transform the test data using loaded scaler object\n",
    "X_test_scaled = scaler_loaded.transform(X_test)\n",
    "# calculate the score using loaded model object\n",
    "print ('score for persisted logistic regression :{0:.2f}'.format(clf_loaded.score(X_test_scaled,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d5de7f",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "742c5482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#training Random Forest Classifier and making prediction\n",
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "rfc_predict[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf1b0a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       164\n",
      "           1       1.00      1.00      1.00       139\n",
      "\n",
      "    accuracy                           1.00       303\n",
      "   macro avg       1.00      1.00      1.00       303\n",
      "weighted avg       1.00      1.00      1.00       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluating Random Forest Classifier\n",
    "print(classification_report(y_test, rfc_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6671e45",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8919ebb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# training Support Vector Machine and making prediction\n",
    "svmc = SVC()\n",
    "svmc.fit(X_train,y_train)\n",
    "svmc_predict = svmc.predict(X_test)\n",
    "svmc_predict[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce9ceaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       164\n",
      "           1       1.00      1.00      1.00       139\n",
      "\n",
      "    accuracy                           1.00       303\n",
      "   macro avg       1.00      1.00      1.00       303\n",
      "weighted avg       1.00      1.00      1.00       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rfc_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed8621a",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11e01fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# training Decision Tree Classifier\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "dt_predict = decision_tree.predict(X_test)\n",
    "dt_predict[:2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30ec17a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       164\n",
      "           1       1.00      1.00      1.00       139\n",
      "\n",
      "    accuracy                           1.00       303\n",
      "   macro avg       1.00      1.00      1.00       303\n",
      "weighted avg       1.00      1.00      1.00       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, dt_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c657c985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "## Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_predict = nb.predict(X_test)\n",
    "nb_predict[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52f6526e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       164\n",
      "           1       1.00      1.00      1.00       139\n",
      "\n",
      "    accuracy                           1.00       303\n",
      "   macro avg       1.00      1.00      1.00       303\n",
      "weighted avg       1.00      1.00      1.00       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, nb_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87d9bf86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "result = lr.fit(X_train, y_train)\n",
    "lr_predict = lr.predict(X_test)\n",
    "lr_predict[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb7be545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.65      0.59       164\n",
      "           1       0.46      0.36      0.40       139\n",
      "\n",
      "    accuracy                           0.51       303\n",
      "   macro avg       0.50      0.50      0.50       303\n",
      "weighted avg       0.51      0.51      0.51       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2d8a07",
   "metadata": {},
   "source": [
    "## Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7dbf957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# creating instances of classifiers to be used in the ensemble\n",
    "lr = LogisticRegression()\n",
    "svm = SVC()\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "nb = GaussianNB()\n",
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485fa5a6",
   "metadata": {},
   "source": [
    "### voting classifier that combines four different estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e295b1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7953795379537953"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "evc = VotingClassifier(estimators=[('svm',svm),('nb',nb),('rf',rf),('lr',lr)], voting='hard')\n",
    "\n",
    "evc.fit(X_train,y_train)\n",
    "evc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae771ae",
   "metadata": {},
   "source": [
    "### bagging classifier with 100 random forest estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50397ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bg = BaggingClassifier(rf, max_samples=0.6, max_features=1.0, n_estimators=100)\n",
    "\n",
    "bg.fit(X_train, y_train)\n",
    "bg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675738d9",
   "metadata": {},
   "source": [
    "### bagging classifier with 100 support vector machine estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0be2ece0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg = BaggingClassifier(nb, max_samples=0.6, max_features=1.0, n_estimators = 100)\n",
    "\n",
    "bg.fit(X_train, y_train)\n",
    "bg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62844e69",
   "metadata": {},
   "source": [
    "### Prepare data for Machine Learning API using Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3537d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import pickle\n",
    "\n",
    "# Load Model and Scaler Files\n",
    "#model_path = os.path.join(os.path.pardir,os.path.pardir,'models')\n",
    "model_path = os.path.join('','','models')\n",
    "\n",
    "model_filepath = os.path.join(model_path, 'lr_model.pkl')\n",
    "scaler_filepath = os.path.join(model_path, 'lr_scaler.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d912c8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models\\\\lr_model.pkl'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd19d423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models\\\\lr_scaler.pkl'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54dccd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfile = bz2.BZ2File(model_filepath, 'w')\n",
    "pickle.dump(X_test, sfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60ce3cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfile = bz2.BZ2File(scaler_filepath, 'w')\n",
    "pickle.dump(y_test, sfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef343385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
